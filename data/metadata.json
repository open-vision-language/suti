{
	"twitter_title": "SuTI: A Generalizable Subject-driven Text-to-Image Generator",
	"twitter_desc": "In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with \\emph{in-context} learning. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization.",
	"website_title": "SuTI: A Generalizable Subject-driven Text-to-Image Generator",
	"paper_title1": "Subject-driven Text-to-Image Generation via",
	"paper_title2": "Apprenticeship Learning",
	"paper_url": "https://wenhuchen.github.io/images/DreamDiffuser.pdf",
	"paper_abstract": "Recent text-to-image generation models like DreamBooth have made remarkable progress in generating highly customized images of a target subject, by fine-tuning an `expert model' for a given subject from a few examples. However, this process is expensive, since a new expert model must be learned for each subject. In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with <i>in-context learning</i>. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization. SuTI is powered by <i>apprenticeship learning</i>, where a single apprentice model is learned from data generated by massive amount of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject. We adopt these clusters to train massive amount of expert models specialized on different subjects. The apprentice model SuTI then learns to mimic the behavior of these experts through the proposed apprenticeship learning algorithm. SuTI can generate high-quality and customized subject-specific images 20x faster than optimization-based SoTA methods. On the challenging DreamBench and DreamBench-v2, our human evaluation shows that SuTI can significantly outperform existing approaches like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen while performing on par with DreamBooth.",
	"acknowledgement": "We thank Boqing Gong, Kaifeng Chen, Steve Seitz, Nicole Brichtova, Andrew Bunner and Jason Baldridge for reviewing on an early version of this paper in depth, with valuable comments and suggestions. We thank Yang Zhao and Shiran Zada for the tons of help and supports on running baseline on the proposed dreambench-v2 dataset. We also thank Kenton Lee for discussions and feedback on the project. Additionally, we thank OVEN and OPERA Team for providing their website template."
}